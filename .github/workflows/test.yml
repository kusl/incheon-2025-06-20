# .github/workflows/test-alternative.yml
# Alternative test workflow that's more reliable and uses built-in GitHub features
name: Test Suite (Alternative)

on:
  push:
    paths:
      - '**/*.cs'
      - '**/*.csproj'
      - '**/test**'
  pull_request:
    paths:
      - '**/*.cs'
      - '**/*.csproj'
      - '**/test**'
  workflow_dispatch:
    inputs:
      test_filter:
        description: 'Test filter (optional)'
        required: false
        type: string
      verbosity:
        description: 'Test verbosity level'
        required: false
        default: 'normal'
        type: choice
        options:
        - quiet
        - minimal
        - normal
        - detailed
        - diagnostic

env:
  DOTNET_VERSION: '9.0.x'
  DOTNET_SKIP_FIRST_TIME_EXPERIENCE: true
  DOTNET_CLI_TELEMETRY_OPTOUT: true

jobs:
  test:
    name: Run Tests
    runs-on: ${{ matrix.os }}
    
    strategy:
      fail-fast: false
      matrix:
        os: [ubuntu-latest, windows-latest]
        configuration: [Debug, Release]
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
    
    - name: Setup .NET
      uses: actions/setup-dotnet@v4
      with:
        dotnet-version: ${{ env.DOTNET_VERSION }}
    
    - name: Cache NuGet packages
      uses: actions/cache@v4
      with:
        path: |
          ~/.nuget/packages
          ${{ github.workspace }}/.nuget/packages
        key: ${{ runner.os }}-nuget-${{ hashFiles('**/*.csproj') }}
        restore-keys: |
          ${{ runner.os }}-nuget-
    
    - name: Restore dependencies
      run: dotnet restore --verbosity minimal
    
    - name: Build solution
      run: dotnet build --configuration ${{ matrix.configuration }} --no-restore --verbosity minimal
    
    - name: Run tests
      shell: bash
      run: |
        VERBOSITY="${{ github.event.inputs.verbosity || 'normal' }}"
        FILTER="${{ github.event.inputs.test_filter }}"
        
        TEST_ARGS="--configuration ${{ matrix.configuration }} --no-build --verbosity $VERBOSITY"
        TEST_ARGS="$TEST_ARGS --results-directory ./TestResults"
        TEST_ARGS="$TEST_ARGS --logger trx --logger \"console;verbosity=$VERBOSITY\""
        
        if [ ! -z "$FILTER" ]; then
          TEST_ARGS="$TEST_ARGS --filter \"$FILTER\""
        fi
        
        # Create results directory
        mkdir -p TestResults
        
        # Run tests and capture exit code
        set +e
        dotnet test Analytics.Data.Tests/Analytics.Data.Tests.csproj $TEST_ARGS
        TEST_EXIT_CODE=$?
        set -e
        
        # Display test results summary
        echo "## Test Results Summary" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "**Platform:** ${{ matrix.os }}" >> $GITHUB_STEP_SUMMARY
        echo "**Configuration:** ${{ matrix.configuration }}" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        
        if [ $TEST_EXIT_CODE -eq 0 ]; then
          echo "✅ **All tests passed!**" >> $GITHUB_STEP_SUMMARY
        else
          echo "❌ **Some tests failed!**" >> $GITHUB_STEP_SUMMARY
        fi
        
        # Count test files
        TRX_FILES=$(find TestResults -name "*.trx" | wc -l)
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "**Test result files:** $TRX_FILES" >> $GITHUB_STEP_SUMMARY
        
        # Exit with the original test exit code
        exit $TEST_EXIT_CODE
    
    - name: Parse test results
      if: always()
      shell: bash
      run: |
        # Parse TRX files and extract test information
        if [ -d "TestResults" ] && [ "$(find TestResults -name '*.trx' | wc -l)" -gt 0 ]; then
          echo "## Detailed Test Results" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          for trx_file in TestResults/*.trx; do
            if [ -f "$trx_file" ]; then
              echo "Processing: $trx_file"
              
              # Extract basic info using grep and basic text processing
              if grep -q "outcome=\"Passed\"" "$trx_file" 2>/dev/null; then
                PASSED_COUNT=$(grep -o "outcome=\"Passed\"" "$trx_file" | wc -l)
              else
                PASSED_COUNT=0
              fi
              
              if grep -q "outcome=\"Failed\"" "$trx_file" 2>/dev/null; then
                FAILED_COUNT=$(grep -o "outcome=\"Failed\"" "$trx_file" | wc -l)
              else
                FAILED_COUNT=0
              fi
              
              TOTAL_COUNT=$((PASSED_COUNT + FAILED_COUNT))
              
              echo "**File:** $(basename "$trx_file")" >> $GITHUB_STEP_SUMMARY
              echo "- Total Tests: $TOTAL_COUNT" >> $GITHUB_STEP_SUMMARY
              echo "- ✅ Passed: $PASSED_COUNT" >> $GITHUB_STEP_SUMMARY
              echo "- ❌ Failed: $FAILED_COUNT" >> $GITHUB_STEP_SUMMARY
              echo "" >> $GITHUB_STEP_SUMMARY
            fi
          done
        else
          echo "No test result files found" >> $GITHUB_STEP_SUMMARY
        fi
    
    - name: Upload test results
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: test-results-${{ matrix.os }}-${{ matrix.configuration }}
        path: TestResults/
        retention-days: 30
    
    - name: Generate test coverage (Linux Release only)
      if: matrix.os == 'ubuntu-latest' && matrix.configuration == 'Release'
      run: |
        # Re-run tests with coverage collection
        dotnet test Analytics.Data.Tests/Analytics.Data.Tests.csproj \
          --configuration Release \
          --no-build \
          --collect:"XPlat Code Coverage" \
          --results-directory ./CoverageResults \
          -- DataCollectionRunSettings.DataCollectors.DataCollector.Configuration.Format=opencover
        
        # Install and run reportgenerator
        dotnet tool install -g dotnet-reportgenerator-globaltool
        reportgenerator \
          "-reports:CoverageResults/**/coverage.opencover.xml" \
          "-targetdir:CoverageReport" \
          "-reporttypes:Html;TextSummary;Badges"
        
        # Add coverage to summary
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "## Code Coverage" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        
        if [ -f "CoverageReport/Summary.txt" ]; then
          echo '```' >> $GITHUB_STEP_SUMMARY
          cat CoverageReport/Summary.txt >> $GITHUB_STEP_SUMMARY
          echo '```' >> $GITHUB_STEP_SUMMARY
        fi
    
    - name: Upload coverage report
      uses: actions/upload-artifact@v4
      if: matrix.os == 'ubuntu-latest' && matrix.configuration == 'Release'
      with:
        name: coverage-report
        path: CoverageReport/
        retention-days: 30
    
    - name: Upload coverage to Codecov
      uses: codecov/codecov-action@v4
      if: matrix.os == 'ubuntu-latest' && matrix.configuration == 'Release'
      with:
        files: CoverageResults/**/coverage.opencover.xml
        flags: unittests
        name: codecov-umbrella
        fail_ci_if_error: false

  test-report:
    name: Test Report
    runs-on: ubuntu-latest
    needs: test
    if: always()
    
    steps:
    - name: Create test summary
      run: |
        echo "## 📊 Test Execution Report" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "**Workflow:** ${{ github.workflow }}" >> $GITHUB_STEP_SUMMARY
        echo "**Trigger:** ${{ github.event_name }}" >> $GITHUB_STEP_SUMMARY
        echo "**Branch:** ${{ github.ref_name }}" >> $GITHUB_STEP_SUMMARY
        echo "**Commit:** ${{ github.sha }}" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        
        # Check overall test results
        if [ "${{ needs.test.result }}" == "success" ]; then
          echo "### ✅ Overall Result: SUCCESS" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "All tests passed across all platforms and configurations!" >> $GITHUB_STEP_SUMMARY
        elif [ "${{ needs.test.result }}" == "failure" ]; then
          echo "### ❌ Overall Result: FAILURE" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "Some tests failed. Please check the individual job results for details." >> $GITHUB_STEP_SUMMARY
        else
          echo "### ⚠️ Overall Result: ${{ needs.test.result }}" >> $GITHUB_STEP_SUMMARY
        fi
        
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "### 🎯 Test Matrix Results" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "| Platform | Configuration | Status |" >> $GITHUB_STEP_SUMMARY
        echo "|----------|---------------|--------|" >> $GITHUB_STEP_SUMMARY
        echo "| Ubuntu | Debug | ${{ needs.test.result }} |" >> $GITHUB_STEP_SUMMARY
        echo "| Ubuntu | Release | ${{ needs.test.result }} |" >> $GITHUB_STEP_SUMMARY
        echo "| Windows | Debug | ${{ needs.test.result }} |" >> $GITHUB_STEP_SUMMARY
        echo "| Windows | Release | ${{ needs.test.result }} |" >> $GITHUB_STEP_SUMMARY
        
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "### 📁 Artifacts" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "- Test results are available in the job artifacts" >> $GITHUB_STEP_SUMMARY
        echo "- Coverage report is generated for Ubuntu Release configuration" >> $GITHUB_STEP_SUMMARY
        echo "- All artifacts are retained for 30 days" >> $GITHUB_STEP_SUMMARY
        
        # Set exit code based on test results
        if [ "${{ needs.test.result }}" == "failure" ]; then
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### 🔧 Next Steps" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "1. Check the failed job logs for detailed error information" >> $GITHUB_STEP_SUMMARY
          echo "2. Download the test result artifacts for offline analysis" >> $GITHUB_STEP_SUMMARY
          echo "3. Fix the failing tests and push a new commit" >> $GITHUB_STEP_SUMMARY
          exit 1
        fi